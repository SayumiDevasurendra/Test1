# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O3UXcf25b_6VYbcdIpDJqLFNnBizobpE
"""


import streamlit as st
from transformers import pipeline
from keybert import KeyBERT
import gensim
from gensim import corpora
from pyngrok import ngrok

# Connect to the port directly (port should be an integer)
public_url = ngrok.connect(8501)
public_url

# Text Summarization
summarizer = pipeline('summarization')

# Sentiment Analysis
sentiment_analyzer = pipeline('sentiment-analysis')

# Keyword Extraction
kw_model = KeyBERT()

# Topic Modeling Helper
def topic_modeling(texts):
    tokenized_texts = [gensim.utils.simple_preprocess(text) for text in texts]
    dictionary = corpora.Dictionary(tokenized_texts)
    corpus = [dictionary.doc2bow(text) for text in tokenized_texts]
    lda_model = gensim.models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15)
    topics = lda_model.print_topics()
    return topics

# Streamlit App UI
def app():
    st.title("End-to-End Text Summarization and Analysis System")

    uploaded_file = st.file_uploader("Upload a Text File", type=["txt"])
    text = st.text_area("Or Paste your Text Here")

    if uploaded_file is not None:
        text = uploaded_file.read().decode("utf-8")

    if text:
        st.subheader("Text Summarization")
        summary = summarizer(text, max_length=100, min_length=30, do_sample=False)
        st.write(summary[0]['summary_text'])

        st.subheader("Sentiment Analysis")
        sentiment = sentiment_analyzer(text)
        st.write(sentiment)

        st.subheader("Keyword Extraction")
        keywords = kw_model.extract_keywords(text)
        st.write(keywords)

        st.subheader("Topic Modeling")
        topics = topic_modeling([text])
        for topic in topics:
            st.write(topic)

if __name__ == "__main__":
    app()
